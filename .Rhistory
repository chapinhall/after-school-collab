#----------
### PROJECT
#----------
#------------------------------------------------------------------------------------
### Set up pooled AR(1) estimation
# The idea for this approach is that the persistence of time trends may be reasonable
# across geographies, so we can
#   1) rescale to get common levels of geographic values;
#   2) pool to get estimation of persistence, and project; and
#   3) rescale back.
### Rescale to common scale
# XXX Here or earlier, it may be simple to store and work with the data in a long rather than wide format
gMeans <- aggregate(. ~ cca, data = est_cy[, c("cca", estCols)], mean, na.rm=T)
colnames(gMeans)[cn(gMeans) %in% estCols ] <- cn(gMeans)[cn(gMeans) %in% estCols ] %&% "_mu"
g <- merge(est_cy, gMeans, by = c("cca"))
for (e in estCols){
# For the sake of smooth forecasting, replace values below 10 with 10. Otherwise, we get either
# NA or NaN values, or potentially extremely erratic AR predictions resulting from inclusion of these
# terms. Replacing these gives them a low, stable value so that AR predictions, once rescaled, will
# stay low, stable and non-negative.
# Note that these recodings to minimum of 10 only play into the AR estimation to look at trends. The
# actual estimates will be rescaled back to their appropriately lower amounts using the gMeans values
# after the trend shapes are established
g[is.na(g[, e]), e] <- 0
g[g[, e]<10, e] <- 10
}
# Check on patterns of zeros within year/cca combinations
z <- g
for (e in estCols){
z[, e%&%"0s"] <- 1*(z[, e]==0)
}
zeroCounts <- aggregate(. ~ cca, data = z[, c("cca", estCols%&%"0s")], sum)
sum(zeroCounts[, -1]) # Not getting any zeroes
# Rescale the measures using updated means
gMeansAdj <- aggregate(. ~ cca, data = g[, c("cca", estCols)], mean, na.rm=T)
colnames(gMeansAdj) <- colnames(gMeansAdj)%&%"_mu.adj"
colnames(gMeansAdj)[1] <- c("cca")
g <- merge(g, gMeansAdj, by = c("cca"))
plot(g$A0002_Inc0to49_Est_mu[g$A0002_Inc0to49_Est_mu<20], g$A0002_Inc0to49_Est_mu.adj[g$A0002_Inc0to49_Est_mu.adj<20])
# The aim (I believe, looking at this in retrospect) is to ensure that the new measures are all truncated from below at 10
cor(g$A0002_Inc0to49_Est_mu, g$A0002_Inc0to49_Est_mu.adj) # rho = 0.9999984
for (e in estCols) {
g[, e] <- g[, e] / g[, e%&%"_mu.adj"]
}
### Pool, estimate and project
g_lag1 <- g[, c("cca", "year", estCols)]
g_lag2 <- g_lag1
g_lag1$year <- g_lag1$year + 1
g_lag2$year <- g_lag2$year + 2
colnames(g_lag1)[grepl("Est", cn(g_lag1))] <- colnames(g_lag1)[grepl("Est", cn(g_lag1))] %&% "_lag1"
colnames(g_lag2)[grepl("Est", cn(g_lag2))] <- colnames(g_lag2)[grepl("Est", cn(g_lag2))] %&% "_lag2"
mergeVars <- c("cca", "year")
g_cy <- merge(     g[, c(mergeVars, estCols)],
g_lag1[, c(mergeVars, estCols%&%"_lag1")], by = mergeVars, all.x = T)
g_cy <- merge(  g_cy,
g_lag2[, c(mergeVars, estCols%&%"_lag2")], by = mergeVars, all.x = T)
g_cy$time <- g_cy$year - min(g_cy$year)
# Set up functions to forecast estimation. XXX In the future, we may add confidence intervals, or find
#   canned functions that will already do this for us
proj.ar1 <- function(betas, d, h, e){ # d is data with a variable year and a second column, h is the number of periods to project, e is the estimate
n <- nrow(d)
for (i in 0:(h-1)){
newRow <- cbind(d$year[n+i]+1,
d$time[n+i]+1,
betas[[1]] +
betas[[2]]*d[n+i, e] +
betas[[3]]*d$time[n+i])
colnames(newRow) <- colnames(d)
d <- rbind(d, newRow)
}
return(d)
}
proj.ar2 <- function(betas, d, h, e){ # d is data with a variable year and a second column, h is the number of periods to project
n <- nrow(d)
for (i in 0:(h-1)){
newRow <- cbind(d$year[n+i]+1,
d$time[n+i]+1,
betas[[1]] +
betas[[2]]*d[n+i  , e] +
betas[[3]]*d[n+i-1, e] +
betas[[4]]*d$time[n+i])
colnames(newRow) <- colnames(d)
d <- rbind(d, newRow)
}
return(d)
}
#### Apply the projections
for (e in estCols){
myProj1 <- NULL
myProj2 <- NULL
ar1 <- lm(as.formula(paste0(e, " ~ time:factor(cca) + ", e, "_lag1")), data = g_cy)
ar2 <- lm(as.formula(paste0(e, " ~ time:factor(cca) + ", e, "_lag1 + ", e, "_lag2")), data = g_cy)
for (myCca in unique(g_cy$cca)){
newProj1 <- proj.ar1(ar1$coefficients[c("(Intercept)", e%&%"_Est_lag1", "time:factor(cca)"%&%myCca)],
g_cy[g_cy$cca == myCca, c("year", "time", e)], 2, e)
outProj1 <- data.frame(cca = myCca, drop(newProj1, "time"))
myProj1 <- rbind(myProj1, outProj1)
newProj2 <- proj.ar2(ar2$coefficients[c("(Intercept)", e%&%"_lag1", e%&%"_lag2", "time:factor(cca)"%&%myCca)],
g_cy[g_cy$cca == myCca, c("year", "time", e)], 2, e)
newProj2 <- data.frame(cca = myCca, drop(newProj2, "time"))
myProj2 <- rbind(myProj2, newProj2)
} # XXX There's likely a more elegant way to do things than this for loop. ddply?
colnames(myProj1) <- c("cca", "year", e)
colnames(myProj2) <- c("cca", "year", e)
assign(e%&%".proj1", myProj1)
assign(e%&%".proj2", myProj2)
} # End of loop across programs
A0002_Inc0to49_Est.proj1
e
ar1 <- lm(as.formula(paste0(e, " ~ time:factor(cca) + ", e, "_lag1")), data = g_cy)
ar1
A0002_Inc0to49_Est.proj2
###--------------------------------------------------------------
###--------------------------------------------------------------
### PROJECT, COMPARE, AND EXPORT POPULATION PROJECTIONS ESTIMATES
###--------------------------------------------------------------
###--------------------------------------------------------------
rm(list=ls())
library(reshape)
library(ggplot2)
library(forecast)
try(setwd("C:/Users/nmader/Google Drive/Chapin Hall - Population Projections for DFSS/"), silent=T)
try(setwd("H:/CYS/Population projections/2014 - new method/"), silent=T)
source("./code/pov projections ecsd -- helper functions.R")
myAges <- c("0002", "0305", "0612", "1317")
IncRanges <- c("Inc0to49", "Inc50to74", "Inc75to99", "Inc100to124", "Inc125to149", "Inc150to174", "Inc175to184", "Inc185to199",
"IncLt100", "Inc150to184") #
estMeas <- c(IncRanges, "CCAP", "CCAP1", "CCAP2", "CCAPHS")
### Bring in new estimates of poverty and program participation
load("./data/ECSD_estimates_est_acmy.Rda") # This contains the file est_acmy
load("./data/tract-to-puma mappings.Rda")
CcaNames <- read.csv("./data/Community Area Mapping - name to number.csv")
ccaNames <- CcaNames
colnames(ccaNames) <- c("cca", "ccaName")
c.u <- sort(unique(est_acmy$cca))
c.n <- length(c.u)
est_acmy$pre <- "A"
est_cy <- cast(est_acmy, cca + year ~ pre + age + meas, value = "value")
colnames(est_cy) <- gsub("A_", "A", cn(est_cy))
estCols <- cn(est_cy)[!(cn(est_cy) %in% c("cca", "year"))]
#----------
### PROJECT
#----------
#------------------------------------------------------------------------------------
### Set up pooled AR(1) estimation
# The idea for this approach is that the persistence of time trends may be reasonable
# across geographies, so we can
#   1) rescale to get common levels of geographic values;
#   2) pool to get estimation of persistence, and project; and
#   3) rescale back.
### Rescale to common scale
# XXX Here or earlier, it may be simple to store and work with the data in a long rather than wide format
gMeans <- aggregate(. ~ cca, data = est_cy[, c("cca", estCols)], mean, na.rm=T)
colnames(gMeans)[cn(gMeans) %in% estCols ] <- cn(gMeans)[cn(gMeans) %in% estCols ] %&% "_mu"
g <- merge(est_cy, gMeans, by = c("cca"))
for (e in estCols){
# For the sake of smooth forecasting, replace values below 10 with 10. Otherwise, we get either
# NA or NaN values, or potentially extremely erratic AR predictions resulting from inclusion of these
# terms. Replacing these gives them a low, stable value so that AR predictions, once rescaled, will
# stay low, stable and non-negative.
# Note that these recodings to minimum of 10 only play into the AR estimation to look at trends. The
# actual estimates will be rescaled back to their appropriately lower amounts using the gMeans values
# after the trend shapes are established
g[is.na(g[, e]), e] <- 0
g[g[, e]<10, e] <- 10
}
# Check on patterns of zeros within year/cca combinations
z <- g
for (e in estCols){
z[, e%&%"0s"] <- 1*(z[, e]==0)
}
zeroCounts <- aggregate(. ~ cca, data = z[, c("cca", estCols%&%"0s")], sum)
sum(zeroCounts[, -1]) # Not getting any zeroes
# Rescale the measures using updated means
gMeansAdj <- aggregate(. ~ cca, data = g[, c("cca", estCols)], mean, na.rm=T)
colnames(gMeansAdj) <- colnames(gMeansAdj)%&%"_mu.adj"
colnames(gMeansAdj)[1] <- c("cca")
g <- merge(g, gMeansAdj, by = c("cca"))
plot(g$A0002_Inc0to49_Est_mu[g$A0002_Inc0to49_Est_mu<20], g$A0002_Inc0to49_Est_mu.adj[g$A0002_Inc0to49_Est_mu.adj<20])
# The aim (I believe, looking at this in retrospect) is to ensure that the new measures are all truncated from below at 10
cor(g$A0002_Inc0to49_Est_mu, g$A0002_Inc0to49_Est_mu.adj) # rho = 0.9999984
for (e in estCols) {
g[, e] <- g[, e] / g[, e%&%"_mu.adj"]
}
### Pool, estimate and project
g_lag1 <- g[, c("cca", "year", estCols)]
g_lag2 <- g_lag1
g_lag1$year <- g_lag1$year + 1
g_lag2$year <- g_lag2$year + 2
colnames(g_lag1)[grepl("Est", cn(g_lag1))] <- colnames(g_lag1)[grepl("Est", cn(g_lag1))] %&% "_lag1"
colnames(g_lag2)[grepl("Est", cn(g_lag2))] <- colnames(g_lag2)[grepl("Est", cn(g_lag2))] %&% "_lag2"
mergeVars <- c("cca", "year")
g_cy <- merge(     g[, c(mergeVars, estCols)],
g_lag1[, c(mergeVars, estCols%&%"_lag1")], by = mergeVars, all.x = T)
g_cy <- merge(  g_cy,
g_lag2[, c(mergeVars, estCols%&%"_lag2")], by = mergeVars, all.x = T)
g_cy$time <- g_cy$year - min(g_cy$year)
# Set up functions to forecast estimation. XXX In the future, we may add confidence intervals, or find
#   canned functions that will already do this for us
proj.ar1 <- function(betas, d, h, e){ # d is data with a variable year and a second column, h is the number of periods to project, e is the estimate
n <- nrow(d)
for (i in 0:(h-1)){
newRow <- cbind(d$year[n+i]+1,
d$time[n+i]+1,
betas[[1]] +
betas[[2]]*d[n+i, e] +
betas[[3]]*d$time[n+i])
colnames(newRow) <- colnames(d)
d <- rbind(d, newRow)
}
return(d)
}
proj.ar2 <- function(betas, d, h, e){ # d is data with a variable year and a second column, h is the number of periods to project
n <- nrow(d)
for (i in 0:(h-1)){
newRow <- cbind(d$year[n+i]+1,
d$time[n+i]+1,
betas[[1]] +
betas[[2]]*d[n+i  , e] +
betas[[3]]*d[n+i-1, e] +
betas[[4]]*d$time[n+i])
colnames(newRow) <- colnames(d)
d <- rbind(d, newRow)
}
return(d)
}
#### Apply the projections
for (e in estCols){
myProj1 <- NULL
myProj2 <- NULL
ar1 <- lm(as.formula(paste0(e, " ~ time:factor(cca) + ", e, "_lag1")), data = g_cy)
ar2 <- lm(as.formula(paste0(e, " ~ time:factor(cca) + ", e, "_lag1 + ", e, "_lag2")), data = g_cy)
for (myCca in unique(g_cy$cca)){
newProj1 <- proj.ar1(ar1$coefficients[c("(Intercept)", e%&%"_lag1", "time:factor(cca)"%&%myCca)],
g_cy[g_cy$cca == myCca, c("year", "time", e)], 2, e)
outProj1 <- data.frame(cca = myCca, drop(newProj1, "time"))
myProj1 <- rbind(myProj1, outProj1)
newProj2 <- proj.ar2(ar2$coefficients[c("(Intercept)", e%&%"_lag1", e%&%"_lag2", "time:factor(cca)"%&%myCca)],
g_cy[g_cy$cca == myCca, c("year", "time", e)], 2, e)
newProj2 <- data.frame(cca = myCca, drop(newProj2, "time"))
myProj2 <- rbind(myProj2, newProj2)
} # XXX There's likely a more elegant way to do things than this for loop. ddply?
colnames(myProj1) <- c("cca", "year", e)
colnames(myProj2) <- c("cca", "year", e)
assign(e%&%".proj1", myProj1)
assign(e%&%".proj2", myProj2)
} # End of loop across programs
### Rescale to individual scales
for (e in estCols){
p1 <- get(e%&%".proj1")
p2 <- get(e%&%".proj2")
if (e == estCols[1]) {
proj1 <- p1
proj2 <- p2
} else {
proj1 <- merge(proj1, p1, by = c("cca", "year"))
proj2 <- merge(proj2, p2, by = c("cca", "year"))
}
}
proj1$projType <- "ar1"
proj2$projType <- "ar2"
proj_ar <- rbind(proj1, proj2)
proj_cols <- !(cn(proj_ar) %in% c("cca", "year", "projType"))
colnames(proj_ar)[proj_cols] <- colnames(proj_ar)[proj_cols] %&% "_proj"
proj1
proj_cy <- merge(proj_ar, gMeans, by = c("cca"))
for (e in estCols){
proj_cy[, e%&%"_proj"] <- proj_cy[, e%&%"_proj"] * proj_cy[, e%&%"_mu"]
}
proj_cy <- proj_cy[, !grepl("_mu", cn(proj_cy))]
proj_cy <- merge(proj_cy, ccaNames, by = c("cca"))
# Recreate city-wide calculations
proj_y <- aggregate(. ~ year + projType, proj_cy[, c("year", "projType", estCols %&% "_proj")], sum)
proj_y$cca <- 0
proj_y$ccaName <- "City of Chicago"
proj_cy <- rbind(proj_cy[, c("cca", "ccaName", "year", "projType", estCols %&% "_proj")],
proj_y[, c("cca", "ccaName", "year", "projType", estCols %&% "_proj")])
proj_cy <- proj_cy[order(proj_cy$cca, proj_cy$year),]
rownames(proj_cy) <- NULL
head(proj_cy)
proj_cy[1:20, 1:6]
table(proj_cy$year)
proj_cy <- proj_cy[proj_cy$projType == "ar1", c("cca", "year", estCols %&% "_proj")]
for (e in estCols){
proj_cy[, e %&% "_proj"] <- round(proj_cy[, e %&% "_proj"], 0)
}
proj_cy$A0002_CCAP_Est_proj <- proj_cy$A0002_CCAP1_Est_proj + proj_cy$A0002_CCAP2_Est_proj
proj_cy$A0305_CCAP_Est_proj <- proj_cy$A0305_CCAP1_Est_proj + proj_cy$A0305_CCAP2_Est_proj
dropCCAPCols <- grep("A..1._CCAP", cn(proj_cy), value = T)
proj_cy <- drop(proj_cy, dropCCAPCols)
# Save
save(proj_cy, file = "./data/ecsd_proj_data.Rda")
###--------------------------------------------------------------
###--------------------------------------------------------------
### PROJECT, COMPARE, AND EXPORT POPULATION PROJECTIONS ESTIMATES
###--------------------------------------------------------------
###--------------------------------------------------------------
rm(list=ls())
library(reshape)
library(ggplot2)
library(forecast)
try(setwd("C:/Users/nmader/Google Drive/Chapin Hall - Population Projections for DFSS/"), silent=T)
try(setwd("H:/CYS/Population projections/2014 - new method/"), silent=T)
source("./code/pov projections ecsd -- helper functions.R")
myAges <- c("0002", "0305", "0612", "1317")
IncRanges <- c("Inc0to49", "Inc50to74", "Inc75to99", "Inc100to124", "Inc125to149", "Inc150to174", "Inc175to184", "Inc185to199",
"IncLt100", "Inc150to184") #
estMeas <- c(IncRanges, "CCAP", "CCAP1", "CCAP2", "CCAPHS")
#-------------------------------------------------
### PREPARE FORMAT FOR POVERTY ESTIMATES -- PART A
#-------------------------------------------------
# Bring in estimates/projections data and the FPL codes
# XXX Am assuming that the data set is long by year, age, fpl, and cca
load("./data/ecsd_proj_data.Rda")
fpl_mapping <- read.csv("./data/FPL_category_mapping.csv")
fpl_mapping <- within(fpl_mapping, {
fpl_desc_8 <- f.to.c(fpl_desc_8)
fpl_desc_9 <- f.to.c(fpl_desc_9)
})
fpl_mapping <- unique(fpl_mapping[, c("fpl_cat_8", "fpl_desc_8")]) # Need to get rid of the duplication with cat 9
proj_cy <- proj_cy[proj_cy$year %in% c(2009, 2013), ]
proj_cy[1:12, 1:6]
proj_cy <- proj_cy[proj_cy$year %in% c(2009, 2013) & proj_cy$cca != 0, ]
proj_cy[1:12, 1:6]
proj_acmy <- melt(proj_cy, id = c("cca", "year"), variable = "est")
proj_acmy <- within(proj_acmy, {
est <- f.to.c(est)
age <- substr(est, 2, 5)
meas <- gsub("^......", "", est)
meas <- gsub("_Est_proj", "", meas)
})
proj_acmy_fpl <- merge(proj_acmy, fpl_mapping, by.x = "meas", by.y = "fpl_desc_8")
unique(proj_acmy_fpl[, c("meas", "fpl_cat_8")])
proj_acmy_fpl <- within(proj_acmy_fpl, var <- p0("pov", age, "_", year, "_", fpl_cat_8))
proj_c.amy_0005 <- cast(proj_acmy_fpl[, c("cca", "var", "value")], cca ~ var, value = "new")
proj_c.amy_0005 <- proj_c.amy_0005[proj_c.amy_0005$cca != 0, ]
proj_acy.m <- cast(proj_acmy[proj_acmy$age %in% c("0612", "1317"), c("age", "cca", "year", "meas", "value")],
age + cca + year ~ meas, value = "value")
proj_acy.m <- as.data.frame(within(proj_acy.m, lt100 <- Inc0to49 + Inc50to74 + Inc75to99))
proj_acmy_temp <- melt(proj_acy.m, id = c("age", "cca", "year"), variable = "meas")
proj_acmy_temp$age[proj_acmy_temp$age == "0612"] <- "age612"
proj_acmy_temp <- within(proj_acmy_temp, var <- p0(age, meas, "_", year))
proj_acmy_temp$age[proj_acmy_temp$age == "1317"] <- "age1317"
proj_c.amy_617 <- cast(proj_acmy_temp[proj_acmy_temp$meas == "lt100",], cca ~ age + meas + year, value = "value")
proj_c.amy <- merge(proj_c.amy_0005, proj_c.amy_617, by = "cca")
write.csv(proj_c.amy, "./output/ecsd_poverty_estimates_PartA.csv")
?write.csv
write.csv(proj_c.amy, "./output/ecsd_poverty_estimates_PartA.csv", row.names = F)
write.csv(proj_c.amy, "./output/ecsd_poverty_estimates_PartA.csv", row.names = F)
###--------------------------------------------------------------
###--------------------------------------------------------------
### PROJECT, COMPARE, AND EXPORT POPULATION PROJECTIONS ESTIMATES
###--------------------------------------------------------------
###--------------------------------------------------------------
rm(list=ls())
library(reshape)
library(ggplot2)
library(forecast)
try(setwd("C:/Users/nmader/Google Drive/Chapin Hall - Population Projections for DFSS/"), silent=T)
try(setwd("H:/CYS/Population projections/2014 - new method/"), silent=T)
source("./code/pov projections ecsd -- helper functions.R")
myAges <- c("0002", "0305", "0612", "1317")
IncRanges <- c("Inc0to49", "Inc50to74", "Inc75to99", "Inc100to124", "Inc125to149", "Inc150to174", "Inc175to184", "Inc185to199",
"IncLt100", "Inc150to184") #
estMeas <- c(IncRanges, "CCAP", "CCAP1", "CCAP2", "CCAPHS")
#-------------------------------------------------
### PREPARE FORMAT FOR POVERTY ESTIMATES -- PART A
#-------------------------------------------------
# Bring in estimates/projections data and the FPL codes
# XXX Am assuming that the data set is long by year, age, fpl, and cca
load("./data/ecsd_proj_data.Rda")
fpl_mapping <- read.csv("./data/FPL_category_mapping.csv")
fpl_mapping <- within(fpl_mapping, {
fpl_desc_8 <- f.to.c(fpl_desc_8)
fpl_desc_9 <- f.to.c(fpl_desc_9)
})
fpl_mapping <- unique(fpl_mapping[, c("fpl_cat_8", "fpl_desc_8")]) # Need to get rid of the duplication with cat 9
proj_cy <- proj_cy[proj_cy$year %in% c(2009, 2013) & proj_cy$cca != 0, ]
proj_acmy <- melt(proj_cy, id = c("cca", "year"), variable = "est")
proj_acmy <- within(proj_acmy, {
est <- f.to.c(est)
age <- substr(est, 2, 5)
meas <- gsub("^......", "", est)
meas <- gsub("_Est_proj", "", meas)
})
proj_acmy_fpl <- merge(proj_acmy, fpl_mapping, by.x = "meas", by.y = "fpl_desc_8")
#unique(proj_acmy_fpl[, c("meas", "fpl_cat_8")])
# Variable naming conventions:
# Variable name: "povAAAA_YYYY_F" where YYYY is year, AAAA is 4-digit age range value, and F is FPL category 1-8
proj_acmy_fpl <- within(proj_acmy_fpl, var <- p0("pov", age, "_", year, "_", fpl_cat_8))
proj_c.amy_0005 <- cast(proj_acmy_fpl[proj_acmy_fpl$age %in% c("0002", "0305"), c("cca", "var", "value")], cca ~ var, value = "new")
proj_c.amy_0005 <- proj_c.amy_0005[proj_c.amy_0005$cca != 0, ]
# Perform aggregations across FPL for 0612 and 1317
# For ages 0612 and 1317, summarize to lt 100%
proj_acy.m <- cast(proj_acmy[proj_acmy$age %in% c("0612", "1317"), c("age", "cca", "year", "meas", "value")],
age + cca + year ~ meas, value = "value")
proj_acy.m <- as.data.frame(within(proj_acy.m, lt100 <- Inc0to49 + Inc50to74 + Inc75to99))
proj_acmy_temp <- melt(proj_acy.m, id = c("age", "cca", "year"), variable = "meas")
proj_acmy_temp$age[proj_acmy_temp$age == "0612"] <- "age612"
proj_acmy_temp$age[proj_acmy_temp$age == "1317"] <- "age1317"
proj_acmy_temp <- within(proj_acmy_temp, var <- p0(age, meas, "_", year))
proj_c.amy_617 <- cast(proj_acmy_temp[proj_acmy_temp$meas == "lt100",], cca ~ age + meas + year, value = "value")
# Join estimates and export
proj_c.amy <- merge(proj_c.amy_0005, proj_c.amy_617, by = "cca")
write.csv(proj_c.amy, "./output/ecsd_poverty_estimates_PartA.csv", row.names = F)
partB_c <- proj_c.amy_0005[, c("cca", grep("2013", cn(proj_c.amy_0005), value = T))]
partB_c
partB_c <- within(partB_c, {
hsEligPop_02 <- pov0002_2013_1 + pov0002_2013_2 + pov0002_2013_3
hsEligPop_35 <- pov0305_2013_1 + pov0305_2013_2 + pov0305_2013_3
})
cn(partB_c)
head(proj_acmy)
proj_acmy$est_year <- p0(proj_acmy$est, "_", proj_acmy$year)
proj_acy.m <- cast(proj_acmy[, c("cca", "est_year", "value")], cca ~ est_year, value = "value")
head(proj_acy.m)
proj_acmy$est_year <- p0(proj_acmy$est, "_", proj_acmy$year)
proj_acy.m <- cast(proj_acmy[proj_acmy$year == 2013, c("cca", "est", "value")], cca ~ est_year, value = "value")
proj_acmy$est_year <- p0(proj_acmy$est, "_", proj_acmy$year)
proj_acy.m <- cast(proj_acmy[proj_acmy$year == 2013, c("cca", "est", "value")], cca ~ est, value = "value")
head(proj_acy.m)
table(proj_acmy$est)
proj_acy.m_ccap <- within(proj_acy.m, {
SubEligPop_02 <- A0002_CCAP_Est_proj
SubEligPop_35 <- A0305_CCAP_Est_proj
Sub_hs_eligPop_02 <- A0002_CCAPHS_Est_proj
Sub_hs_eligPop_35 <- A0305_CCAPHS_Est_proj
unemp1prt_02 <- A0002_CCAP1_Est_proj
unemp2prt_02 <- A0002_CCAP2_Est_proj
unemp1prt_35 <- A0305_CCAP1_Est_proj
unemp2prt_35 <- A0305_CCAP2_Est_proj
test_02 <- unemp1prt_02 + unemp2prt_02
})
proj_acy.m_ccap[, c("test_02", "SubEligPop_2")]
proj_acy.m_ccap[, c("test_02", "SubEligPop_02")]
sum(proj_acy.m_ccap$test_02 != proj_acy.m_ccap$SubEligPop_02
)
proj_c_ccap <- cast(proj_acmy[proj_acmy$year == 2013, c("cca", "est", "value")], cca ~ est, value = "value")
proj_c_ccap <- within(proj_c_ccap, {
SubEligPop_02 <- A0002_CCAP_Est_proj
SubEligPop_35 <- A0305_CCAP_Est_proj
Sub_hs_eligPop_02 <- A0002_CCAPHS_Est_proj
Sub_hs_eligPop_35 <- A0305_CCAPHS_Est_proj
unemp1prt_02 <- A0002_CCAP1_Est_proj
unemp2prt_02 <- A0002_CCAP2_Est_proj
unemp1prt_35 <- A0305_CCAP1_Est_proj
unemp2prt_35 <- A0305_CCAP2_Est_proj
#test_02 <- unemp1prt_02 + unemp2prt_02 ... produces the same value as SubEligPop_02
})
dim(partB_c)
partB_c <- merge(partB_c, proj_c_ccap, by = "cca")
dim(partB_c)
proj_c_ccap <- cast(proj_acmy[proj_acmy$year == 2013, c("cca", "est", "value")], cca ~ est, value = "value")
proj_c_ccap <- proj_c_ccap[, c("cca", grep("CCAP", cn(proj_c_ccap), value = T))]
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
dim(partB_c)
write.csv(partB_c, "./output/ecsd_poverty_estimates_PartB.csv", row.names = F))
write.csv(partB_c, "./output/ecsd_poverty_estimates_PartB.csv", row.names = F)
proj_c_ccap <- drop(proj_c_ccap, grep("_Est", cn(proj_c_ccap)))
source('~/.active-rstudio-document', echo=TRUE)
proj_c_ccap <- cast(proj_acmy[proj_acmy$year == 2013, c("cca", "est", "value")], cca ~ est, value = "value")
proj_c_ccap <- proj_c_ccap[, c("cca", grep("CCAP", cn(proj_c_ccap), value = T))]
proj_c_ccap <- within(proj_c_ccap, {
SubEligPop_02 <- A0002_CCAP_Est_proj
SubEligPop_35 <- A0305_CCAP_Est_proj
Sub_hs_eligPop_02 <- A0002_CCAPHS_Est_proj
Sub_hs_eligPop_35 <- A0305_CCAPHS_Est_proj
unemp1prt_02 <- A0002_CCAP1_Est_proj
unemp2prt_02 <- A0002_CCAP2_Est_proj
unemp1prt_35 <- A0305_CCAP1_Est_proj
unemp2prt_35 <- A0305_CCAP2_Est_proj
#test_02 <- unemp1prt_02 + unemp2prt_02 ... produces the same value as SubEligPop_02
})
cn(proj_c_ccap)
proj_c_ccap <- drop(proj_c_ccap, grep("_Est", cn(proj_c_ccap)))
cn(proj_c_ccap)
proj_c_ccap <- cast(proj_acmy[proj_acmy$year == 2013, c("cca", "est", "value")], cca ~ est, value = "value")
proj_c_ccap <- proj_c_ccap[, c("cca", grep("CCAP", cn(proj_c_ccap), value = T))]
proj_c_ccap <- within(proj_c_ccap, {
SubEligPop_02 <- A0002_CCAP_Est_proj
SubEligPop_35 <- A0305_CCAP_Est_proj
Sub_hs_eligPop_02 <- A0002_CCAPHS_Est_proj
Sub_hs_eligPop_35 <- A0305_CCAPHS_Est_proj
unemp1prt_02 <- A0002_CCAP1_Est_proj
unemp2prt_02 <- A0002_CCAP2_Est_proj
unemp1prt_35 <- A0305_CCAP1_Est_proj
unemp2prt_35 <- A0305_CCAP2_Est_proj
#test_02 <- unemp1prt_02 + unemp2prt_02 ... produces the same value as SubEligPop_02
})
proj_c_ccap <- drop(proj_c_ccap, grep("_Est", cn(proj_c_ccap), value = T))
cn(proj_c_ccap)
partB_c <- merge(partB_c, proj_c_ccap, by = "cca")
write.csv(partB_c, "./output/ecsd_poverty_estimates_PartB.csv", row.names = F)
shiny::runApp('C:/Users/nmader/Google Drive/Thrive Chicago - Engaged in enrichment and academic activities/Data on Schools/cps-compare-pairs-elem')
for (y in 2011:2014) cn(get(p0("ell", y)))
for (y in 2011:2014) print(cn(get(p0("ell", y))))
for (y in 2012:2014){
d <- get(p0("ell", y))
print(cn(d))
d$year <- y
ell <- rbind(ell, d)
}
?aggregate
setwd("~/GitHub/after-school-collab")
getwd()
source("./scripts/helper-functions.r") # XXX Need a way to identify the folder of the current file
?stopif
??stop
?stop
?switch
?stopifnot
